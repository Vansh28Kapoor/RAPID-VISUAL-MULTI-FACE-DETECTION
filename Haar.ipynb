{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc1f400-85ea-49d9-b940-ec85817c2c5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EE 769 Project\n",
    "## HAAR Feature-based Adaboost Cascade Classifier for Face Detection\n",
    "### Sankalp Bhamare, Vansh Kapoor, and Ankur Verma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f72ef0-0d69-4afb-93f3-85de41772f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import Perceptron, RidgeClassifier\n",
    "from skimage.filters import unsharp_mask\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5215d5-376b-436a-9796-c7da9396f608",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2739c00-d573-42a9-a5a0-5b3b26b6e4bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FACE_SIZE = 19 # size of the face detection kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e8a3f-6b74-4eb7-8bc9-462d3b8cccea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Integral Image\n",
    "This is a form of image representation in which each pixel contains the value of integration of rectangle from the top left corner to the current pixel.\n",
    "Storing information in this way allows the rapid computation of integrals, as shown in the function `get_rect(intg_img, si, sj, ei, ej)`, \n",
    "\n",
    "Where `result = intg_img[ei+1, ej+1] - intg_img[si, ej+1] - intg_img[ei+1, sj] + intg_img[si, sj]`\n",
    "\n",
    "> Inorder to speed up computation, the function call is avoided and directly the elements are accessed and integrals are computed in O(1) time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8204a0f-d6f0-43ed-824d-b50c67f94bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_intg_image(img):\n",
    "    \"\"\"\n",
    "    Computes matrix for quick computation of integrals.\n",
    "    \"\"\"\n",
    "    # Create a matrix of zeros with the same dimensions as the input image\n",
    "    intg_img = np.zeros((img.shape[0]+1, img.shape[1]+1) , dtype=np.int64)\n",
    "    \n",
    "    # Iterate over each pixel in the input image\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Calculate the sum of all pixels above and to the left of the current pixel\n",
    "            intg_img[i+1, j+1] = intg_img[i, j+1] + intg_img[i+1, j] - intg_img[i, j] + img[i, j]\n",
    "\n",
    "    # Return the computed integral image\n",
    "    return intg_img\n",
    "\n",
    "def get_rect(intg_img, si, sj, ei, ej):\n",
    "    \"\"\"\n",
    "    Computes integral in rect by top left corner to bottom right\n",
    "    \"\"\"\n",
    "    # Calculate the sum of all pixels within the specified rectangular region\n",
    "    result = intg_img[ei+1, ej+1] - intg_img[si, ej+1] - intg_img[ei+1, sj] + intg_img[si, sj]\n",
    "    \n",
    "    # Return the computed sum of pixels\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c7ab17-a528-4f68-91b9-e9bd2a44092a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Haar Features\n",
    "Haar filters are a type of feature used in object detection, particularly in face detection. They are simple rectangular filters that can be applied to an image to extract certain features.\n",
    "\n",
    "Haar filters work by computing the difference in average intensity between adjacent regions in the image. This is done by computing the integral image of the original image and then applying the filter to it. Haar filters come in different shapes and sizes and are applied at different scales to capture features at different levels of detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c8ceb-a2f8-47ed-9975-cc3dd979b99f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Types of HAAR Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170d4346-ab55-4dcc-8449-1240ab73b632",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Type 1\n",
    "Used for detecting the region between eyes (darker) and cheeks (lighter).\n",
    "\n",
    "![filters/t11_haar.png](filters/t11_haar.png)\n",
    "\n",
    "#### Type 2\n",
    "Used for detecting the region between cheeks (lighter) and nose (darker).\n",
    "\n",
    "![filters/t22_haar.png](filters/t22_haar.png)\n",
    "\n",
    "#### Type 3\n",
    "Used for detecting the nose (darker) with cheeks (lighter) on both the sides.\n",
    "\n",
    "![filters/t33_haar.png](filters/t33_haar.png)\n",
    "\n",
    "#### Type 4\n",
    "Used for detecting eyebrows (darker) with skin (lighter) on both the sides.\n",
    "\n",
    "![filters/t44_haar.png](filters/t44_haar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a2174f-7c61-47b6-bd87-8bf38ffa843b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementation of HAAR features\n",
    "\n",
    "The haar features shown above are simple kernel which are applied across the image, to improve performance integral image representation is used wherein all the rectangle integral (conv. over image) can be computed directly using 4 memory access.\n",
    "\n",
    "The code here implements the method for computation of haar filters and their generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e2a20a-9a53-4987-b710-1540d149eec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_features_from_filter(h, w, filt_type):\n",
    "    \"\"\"\n",
    "    Generates all possible position for a haar filter of a given size.\n",
    "    \"\"\"\n",
    "    gen_features = []\n",
    "    # Iterate over all possible starting positions for the filter in the image\n",
    "    for i in range(FACE_SIZE-h+1):\n",
    "        for j in range(FACE_SIZE-w+1):\n",
    "            # Append the feature parameters (height, width, filter type, starting row, starting column)\n",
    "            gen_features.append((h,w, filt_type, i, j))\n",
    "    return gen_features\n",
    "\n",
    "def generate_haar_filters():\n",
    "    \"\"\"\n",
    "    Generates all possible haar filter features.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to hold all generated Haar features\n",
    "    haar_features= []\n",
    "    # Iterate over all possible filter heights and widths\n",
    "    for i in range(1, FACE_SIZE+1):\n",
    "        for j in range(1, FACE_SIZE+1):\n",
    "            # Append all possible features that can be generated from this filter type, height, and width\n",
    "    \n",
    "            # Check if the filter width is even\n",
    "            if i % 2 == 0:\n",
    "                filter_type = 0 # Set the filter type to horizontal\n",
    "                haar_features += generate_features_from_filter(i, j, filter_type)\n",
    "\n",
    "            # Check if the filter height is even\n",
    "            if j % 2 == 0:\n",
    "                filter_type = 1 # Set the filter type to vertical\n",
    "                haar_features += generate_features_from_filter(i, j, filter_type)\n",
    "    \n",
    "            # Check if the filter width is a multiple of 3\n",
    "            if j % 3 == 0:\n",
    "                filter_type = 2 # Set the filter type to vertical\n",
    "                haar_features += generate_features_from_filter(i, j, filter_type)\n",
    "    \n",
    "            # Check if the filter height is a multiple of 3\n",
    "            if i % 3 == 0:\n",
    "                filter_type = 3 # Set the filter type to horizontal\n",
    "                haar_features += generate_features_from_filter(i, j, filter_type)\n",
    "\n",
    "    return haar_features\n",
    "\n",
    "def compute_haar_feature(intg_img, haar_feature):\n",
    "    \"\"\"\n",
    "    Compute a haar feature over the intgeral image.\n",
    "    \"\"\"\n",
    "    # extract the parameters of the haar_feature tuple\n",
    "    h, w, filt_type, i, j = haar_feature\n",
    "    result = 0\n",
    "\n",
    "    # compute the haar feature value based on the filter type\n",
    "    if filt_type == 0:\n",
    "        result = 2 * ( intg_img[i+h, j+w] - 2*intg_img[i+h//2, j+w] - intg_img[i+h, j] + 2*intg_img[i+h//2, j] + intg_img[i, j+w] - intg_img[i, j]) / (h*w)\n",
    "    elif filt_type == 1:\n",
    "        result = 2*(2*intg_img[h + i, j + w//2] - intg_img[h + i, j + w] - intg_img[h + i, j] - 2*intg_img[i, j + w//2] + intg_img[i, j + w] + intg_img[i, j]) / (h*w)\n",
    "    elif filt_type == 2:\n",
    "        result = (3*intg_img[h + i, j + 2*w//3] - 3*intg_img[h + i, j + w//3] - intg_img[h + i, j + w] + intg_img[h + i, j] - 3*intg_img[i, j + 2*w//3] + 3*intg_img[i, j + w//3] + intg_img[i, j + w] - intg_img[i, j]) / (h*w) * 1.5\n",
    "    elif filt_type == 3:\n",
    "        result = (-intg_img[h + i, j + w] + intg_img[h + i, j] + 3*intg_img[h//3 + i, j + w] - 3*intg_img[h//3 + i, j] - intg_img[i + 2*h//3, j + w] + intg_img[i + 2*h//3, j] - intg_img[i, j + w] + intg_img[i, j])/(h*w)*1.5\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_haar_coef(intg_img, haar_filter_set):\n",
    "    \"\"\"\n",
    "    Compute and return features from a set of haar filter computed on a image.\n",
    "    \"\"\"\n",
    "    return list(np.hstack([compute_haar_feature(intg_img, filt) for filt in haar_filter_set]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250724c4-d907-4909-a84b-7d30d48c52d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading Dataset\n",
    "The code below loads the ML dataset used for training the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e8521c-8637-4b52-8747-419c48a9357d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_folder(folder):\n",
    "    \"\"\"\n",
    "    Load images from the dataset folder.\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    for file in os.listdir(folder):\n",
    "        if \".pgm\" in file:\n",
    "            imgs.append(cv2.imread(folder+\"/\"+file,-1))\n",
    "    return imgs\n",
    "\n",
    "def load_data(folder):\n",
    "    \"\"\"\n",
    "    Load images and process them into training data format.\n",
    "    \"\"\"\n",
    "    train_x_true = load_folder(folder+\"/face\")\n",
    "    train_x_false = load_folder(folder+\"/non-face\")\n",
    "\n",
    "    train_y_true = [1] * len(train_x_true)\n",
    "    train_y_false = [0] * len(train_x_false)\n",
    "\n",
    "    train_x = train_x_true + train_x_false\n",
    "    train_y = train_y_true + train_y_false\n",
    "    train_x = [compute_intg_image(img) for img in train_x]\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b82a5995-2a0d-4484-9438-c3e43d2b4fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, train_y = load_data(\"train\")\n",
    "test_x, test_y = load_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f23818b5-6232-4ca5-a2f0-dfffadd27258",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAACpCAYAAACLUV+QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAk8ElEQVR4nO3de3CU1f0G8CcQEu4JEEgIkHAHQYiUS5oBxwtozGgHlbHq6AzWVqvCiKWtSqeKtbaxMnWslYFWq+jYitoW6qWiiBCqQpAAAoLIJUAgFwRJCBFByfn90cn+DJznW/OavJtkn8/Mzsh59+y+e/Z93xx3z7PfOOecg4iIiEhI2kR7B0RERCS2aPIhIiIiodLkQ0REREKlyYeIiIiESpMPERERCZUmHyIiIhIqTT5EREQkVJp8iIiISKg0+RAREZFQxUd7B85UW1uL0tJSdOnSBXFxcdHeHREREfkGnHOorq5Geno62rT5H59tuCbyxBNPuMzMTJeYmOgmTJjgCgsLv1G/kpISB0A33XTTTTfddGuBt5KSkv/5t75JPvl48cUXMXv2bCxcuBDZ2dl47LHHkJubix07dqBXr15m3y5dugAAHnzwQbRv3/6s7bm5ud5+ycnJ9DHj4/0v05qZsW3OKIXDPqmxnqe2tpZuY7766itve0VFBe2zZ88eb3tlZSXtw7axxwKA7du3e9vLy8tpnyuuuIJu69mzp7d98ODBtE9NTU2DHgsAkpKS6LaG9qk7hn0SExMb/DzsGLGORXaMfPnll7QP28YeCwBOnjzpbX/ttddon48++ohuY+fq1q1baR82Pt27d6d9srOzve0TJkygfVJTU73tnTp1on3atm3rbbfOe3a9sPocP37c23748GHa5+jRo9724uJi2oddYw4cOED77Nixg2674IILvO133HEH7ZOSkuJtZ8eOhb0/1rZ27drRPo35aX2Q89s6RqzHa6jTp09726urqzF8+HDzGlinSSYfjz76KG655Rb84Ac/AAAsXLgQr7/+Op5++mnce++9Zt+6N699+/bo0KHDWdvZi+ratSt9zFiZfHz++ee0D7tAnjp1ivZhf1isP6BsrK2T3Ho83zEA2Bd89h5ZfTp37ky3MUGOxWhPPqz3O8jkg12Iff/jUCchIYFuC3L8sPPO+mPE3oeOHTvSPuwYsY6dsCYfzIkTJ+g2dn4Hee+sP8jWe8cezxpTdn5p8hH9yUedbzIOjb7g9NSpUygqKsKUKVP+/0natMGUKVOwZs2as+5/8uRJHDt2rN5NREREWq9Gn3wcPnwYp0+fPusjytTUVO9H7/n5+UhKSorc+vXr19i7JCIiIs1I1KO2c+bMQVVVVeRWUlIS7V0SERGRJtToaz5SUlLQtm3bsxYmVVRUIC0t7az7JyYmer9//eyzz7zfPbLFhEVFRXSf+vTp4223PmVh3x9WVVXRPmzNhfUdIft+1/puni0uY2MDAK+88oq33Rq3INgYWAsdrUV+55xzjrfd+n6XfY9s9Qny/W6Q9QnsO1nrO1R2LHzxxRe0T3V1tbfdWhfEvhO2xo0dv9bXp9Y5tH79em+7tYCNLQRlCyoB4IUXXvC2WwtbL774Ym+7dfwGWZ/Axq6srIz2Wbt2rbe9oKCA9mH/o8eOHYCfx9aC7aysLLqNXbOs6wXrY63XYWvHLEHWb7BzyHosts1aoxFk/Q97HmtNl3Ut+7Ya/ZOPhIQEjB07FitWrIi01dbWYsWKFcjJyWnspxMREZEWpknSLrNnz8b06dMxbtw4TJgwAY899hhqamoi6RcRERGJXU0y+bj22mvx6aef4v7770d5eTnOO+88LFu2jH48KiIiIrGjyX5efebMmZg5c2ZTPbyIiIi0UFFPu4iIiEhsaXaF5epUVlZ6UzDvv/++9/7nnXcefayFCxd62/v370/7sITBc889R/uwlf/W87BkhvXLhOxnwseNG0f7sGTEvn37aB+2Qrxv3760D1vdbyUPdu7cSbd9+umn3nbrVzJ79OjhbbdW5LNUi7VKnv2kf5CV9Z999hnddvDgQW+79bPV7OfsrdXrLFlk/ZQ9O06tX3JlrwcAXZQ+fvx42oftn/Xz6mwftmzZQvuwFIpV1iDIr9Oyc8V6vzds2OBtt45FNqZWGQJ2Pq5cuZL2sZJ769at87bfcssttA87j9PT02mfESNGeNsnTZpE+wwZMsTbbo1pkOs562ONG7uesyQkAOzevdvbbqUkWSKUHSNWUupM+uRDREREQqXJh4iIiIRKkw8REREJlSYfIiIiEipNPkRERCRUmnyIiIhIqJpt1DY+Pt5bfGnXrl3e+x86dIg+1pgxY7ztf/vb32ifiy66yNtuFeZi8aPZs2fTPtnZ2d72l19+mfZhsboPPviA9mEFs6zXM2zYMG/7gAEDaJ+PP/7Y224VTrOKeQUp1scilhkZGbQPi+lZsbqUlJQGPRYAnDx50tu+efNm2mfjxo3e9k2bNtE+LPLWq1cv2oe9R9Z7x14Pi2QCvNAjwMe7sLCQ9mHxe7ZvAC9CZo0PK3Z2+PBh2oc9nhW9LC0t9bZbFb9ZlNSKG3fu3Nnbbl0T2DFvRbgPHDhAt7GCgb4ipHXY/r333nu0z+uvv+5tZwUGAeDHP/6xt/3qq6+mfVi02iosxwoGvvXWW7QP+/tgnXesgJx1PrK48Xe/+11vu3Vcn0mffIiIiEioNPkQERGRUGnyISIiIqHS5ENERERCpcmHiIiIhKrZpl2++uor7wrqTz75xHv/7du308dixc6sYl5sNbFVMIulQN544w3aZ8KECd723Nxc2ocVnrKKOzG+RFGdbt26edv//e9/0z6dOnXytlur7lnBLoAnFqwEBiuuxIoxWftgpWrYinzrGGGr3tkqeYAnM3r37k37sKJ31hgUFRV5263igyytYBVbs46FtWvXetuthBVbef/000/TPizNZhVNZMeIlUJh42MVANuzZw/dxrCUwX/+8x/ahyXTrLQWS5pYxeisxBhL6YwdO5b2YcXorOs5u15YxduWLVvmbWcJRQDIzMxs8PO8++673valS5fSPiz1aSW8hg8f7m2fNm0a7cPOLcY6rs+kTz5EREQkVJp8iIiISKg0+RAREZFQafIhIiIiodLkQ0REREKlyYeIiIiEqtlGbQ8cOOCNObLIFIs4AUBNTY23nUVwAV6Ex+rDivrMmjWL9klNTfW2WwWupk6d6m3/5z//SfuwCBR7fgDYu3evt92K4rHiW1aU1IpesgJpVqSM9bGKO7HCWG3a8Pl5+/btG/w8jBXPZZFaa99YJHLbtm20z86dO73t1lgPHDjQ224dv1aclUWBnXO0T2VlpbfdKgDGjnv2nlrbrIgnOx+siHt5ebm33Ro3dk5aUfEPP/zQ2z5x4kTah8Vc2bED2FHOrKwsb7tVJI4VYrOK2+Xk5Hjb+/XrR/uw69/u3btpn5EjR3rb2XEAAP379/e2T548mfZhBd9YVB3g5/6TTz5J+7Dz7pJLLmnQ/X0a/ZOPBx54AHFxcfVuLF8sIiIisadJPvkYOXIk3n777f9/EmOWLyIiIrGlSWYF8fHx9Ncfz3Ty5Ml6H+tav3YpIiIiLV+TLDjduXMn0tPTMXDgQNxwww3Yv38/vW9+fj6SkpIiN+s7OBEREWn5Gn3ykZ2djUWLFmHZsmVYsGABiouLcf7559NFgHPmzEFVVVXkZtVJEBERkZav0b92ycvLi/z36NGjkZ2djczMTLz00kv44Q9/eNb9ExMTvSv9R44c6W1nK9itIlsHDx70tm/dupX2YSv8U1JSaB+W2mArkwG+OthaNcwSNzfeeCPtc+TIEbqNYckiKyHDxtRa7T106FC6jaV0WBoJAA4dOuRtt5JKLJ3BUiMALyzXo0cP2oclr6ziW2zfrNfDCo1ZySJW5Mt6v9k2q8CU9d6xVIKVIGLFDFlRN+vxrARRVVWVt90qGsbeV2sdHCskaKU5EhISvO0sSQEA06dP97az6yXA0zODBw+mfcaPH0+3scKaY8aMafA+WO8dG1OrT2lpqbfdeh+CYGNnjSn7+2Bd59n/2Hfu3Jn2YccpO66tc/tMTf47H8nJyRg6dCitwiciIiKxpcknH8ePH8fu3bvNTyZEREQkdjT65ONnP/sZCgoKsHfvXrz//vu46qqr0LZtW1x//fWN/VQiIiLSAjX6mo8DBw7g+uuvx5EjR9CzZ09MmjQJa9euRc+ePRv7qURERKQFavTJx+LFixv7IUVERKQVUWE5ERERCVWz/d3zyy67zBsBYgXkrOgaK/bDooVAwwrk1CksLPS2W5E/JkhxsuLiYrrt5z//ubc9KSmJ9mExNKuQ1hVXXOFtZxFTgBfSAnjcl7Vb26xYHYuGWlHbjIwMbzuLflr7kJycTPuwY9EaAxb/tAowsgijVWyNRRitXyq2km8spsyipACPClqRSHa9YIXtAF6w0IpJs/fbej3sK2oWnwaAQYMGedutY4Qdv+yxAKCiosLbzmLIgH2dZdefbt260T5sTK3ilUF+0oD94GWQ57EK/LHIfJDnsWL+rMaa9beGjTU7rqwCmWc99je+p4iIiEgj0ORDREREQqXJh4iIiIRKkw8REREJlSYfIiIiEipNPkRERCRUzTZq26lTJ29kkVXNsyI+LBZkRfFYFdbdu3fTPgUFBd52VrkR4HEqK/7Eon179uyhfZ566ilv+8SJE2kfVo/HiiOWlZV52624plX3h0UirQghi6FZlXVZfNiqWMqqzVqvlR1zVrVkVmHZOn7ZtiAVOYNEVq3zkVUdBnhs1oqzsvG24qzs+GHHL8CPESsmzaLI1vHLKtFu3LiR9mFR9r59+9I+bL+t18OinFZc3no8FuW0oqnsmmkdp2y8g/ykgXV+s/22Ir3sHLL6sNdjVZUN45rQkMfSJx8iIiISKk0+REREJFSafIiIiEioNPkQERGRUGnyISIiIqFqtmmXjz/+2LtSfNKkSd77WyuDWVrAKn61bds2b/vixYtpn6uvvtrbfvjwYdqHrZy2CuUdPHjQ284KIQHAmjVrvO1W0Tu2gt1a7c0SBlu2bKF92Op+67mCrGxnxwHAC8hZ7wNLZlgF7Ng263nYvlmJkiDF1tjK/yCJAOv1WOPD3m+rWB9LlFiFuYKkXdiYWvtmFW5k2HFqFVsrLS31tg8YMID2YcdPkOPXSpJZyR6WzgiSsLL+BrDHs9JsQY77IAVJgzwPS9VY5x17niD7zM4t65w7kz75EBERkVBp8iEiIiKh0uRDREREQqXJh4iIiIRKkw8REREJlSYfIiIiEqoGR21Xr16NefPmoaioCGVlZViyZAmuvPLKyHbnHObOnYsnn3wSlZWVmDhxIhYsWIAhQ4Y06Hk2bdrkjYKxKCcreAQAO3fu9LazQlEAsHfvXm+7FQHbsWOHt/2hhx6ifdjrseJpR44c8bZbMSsWYfzHP/7R4H2z4rnWPjCXXnop3cYKilnP05jF6KwYXJCCTCyKZsXdWB8rOhwkastilNYYBCnyZUU52TgEKaJnxShZzL6qqor2YbFZVtTN6mO9Hhalt/ocPXrU2269dyyuGaTgphW/r6yspNuC/NRAY5531nvHXmv37t0b/PwWtm/W9Ypdm4PEdi1sDFhE2romnanBn3zU1NQgKysL8+fP925/5JFH8Pjjj2PhwoUoLCxEp06dkJuba1ZCFRERkdjR4P9NzcvLQ15ennebcw6PPfYYfvnLX2Lq1KkAgOeeew6pqalYunQprrvuum+3tyIiItLiNeqaj+LiYpSXl2PKlCmRtqSkJGRnZ9Nf2Dx58iSOHTtW7yYiIiKtV6NOPup+jjs1NbVee2pqKv2p7vz8fCQlJUVu1k+Ei4iISMsX9bTLnDlzUFVVFbmVlJREe5dERESkCTVqYbm0tDQAQEVFBXr37h1pr6iowHnnneftk5iY6E21bN682bvi+cCBA97H6du3L92vjIwMbztb7Q2c/elNndzcXNrnkUce8bYXFxfTPmzlNltNDPBEgFV4qmvXrt52KxHAth0/fpz2YayEAyucBgDJycnedmtVN3suax/Y41krztk4WMdVdXW1t90aA7bfVhEn9t41dvqB7Zs1bkFSR0HeBzbW1jbrvbPOY4alUKxjcfPmzd526/1mBeSsRB9LCAZJeFmvh40BwM9vViwQ4Me2lRhjKSbruGLXTOsYCVK8LUixvhMnTnjbrdRRkJQQez0sjdSQtGOjfvIxYMAApKWlYcWKFZG2Y8eOobCwEDk5OY35VCIiItJCNfiTj+PHj2PXrl2RfxcXF2PTpk3o3r07MjIycNddd+Ghhx7CkCFDMGDAANx3331IT0+v91sgIiIiErsaPPlYv349Lrroosi/Z8+eDQCYPn06Fi1ahLvvvhs1NTW49dZbUVlZiUmTJmHZsmXmx0EiIiISOxo8+bjwwgvN76/i4uLw4IMP4sEHH/xWOyYiIiKtU9TTLiIiIhJbNPkQERGRUDVq1LYxHTt2zBvbYREjK1bHImVWLGjUqFHe9rFjx9I+t912m7f9iSeeoH327NlDtzGssBsrYgXwKB6LLgM8wmhFwBgrimfFfVk8LEj809oHVhCJxR4BXrDQin0fPnzY226NQa9evbzt7D0FgkW4WZTTihYy1jFibWPRR+v8ZsepVU+KPR4rZAgAWVlZ3nar0CI7rqz3gT3e/v37aR927luF8tj1z/fTB3XYe2e9p9bX9EHi/Na5wrDzwYoiM1YMmL1WawzYtiBRequwG3tfg/xsAWMd12c9doMeWURERORb0uRDREREQqXJh4iIiIRKkw8REREJlSYfIiIiEipNPkRERCRUzTZqW1tb640asViQFRdi8TmrCmznzp297RUVFQ3uk56eTvuwaBSLFAM8NmZFIrt37+5ttyJg+/bt87ZblSCDYPFTIFhFYhb3siJ6LHrJxgAAPv30U287q9QJAD179vS2W/FGFrlj7ynA45rW+82OOStul5CQ4G23xjpItc4gVZErKysbvA9WjJJts/qw8bGi4uz9tq5XbNzKyspoHzamVikMdvxYVZmt/Wav1Xq8INc/dk1YuXIl7VNYWOhtv/POO2kf9rMOa9eupX3YcXrJJZfQPn369PG2W1FbFj23/nYy7LhW1FZERESaLU0+REREJFSafIiIiEioNPkQERGRUGnyISIiIqFqtmmX+Ph4b+Gjrl27eu9vFXdKSUnxtq9fv572YdusJENOTo63/dxzz6V92Ipzq+AbKxZlpQhWr17tbbdWJ7NiVWylM8CTMFbKwnqt/fv397bX1NTQPixpYRXZKi0t9bZbqSP2moKkalhyBgBKSkq87VZRrMGDB3vbreKD7LVa6SZ2PgYpJmY9l1Xwrbi42Ntund/Hjh3ztlvXEZZIYgkHgCfg2PMDPLFgJX5YYuHo0aO0D9tv671jzxOk8J/FKvrJzn2rkCBLlFjXc/aafvGLX9A+7Bhhf4MA4Pvf/36D942dQ1ZyhV3rgxSObAz65ENERERCpcmHiIiIhEqTDxEREQmVJh8iIiISKk0+REREJFSafIiIiEioGhy1Xb16NebNm4eioiKUlZVhyZIluPLKKyPbb7rpJjz77LP1+uTm5mLZsmUNeh4WC2IxMKtQ09KlS73t69ato31YATkrqvjee+95260iSSweGySqaI0BezwWlQR4bCtI4SkrrhkkZmqND3vvysvLaZ8dO3Y0uA8rmGUVfGPH9SeffEL7sNdjvXf9+vXztnfq1In2Ye+3FfkbMWKEt906Fq0YJYv7WmPKzsm8vDza5+OPP/a2W+dq3759ve3Wa2XxT1ZQDeBR0q1bt9I+7JycNGkS7ROk+CCL7lrx6V27dtFtLO7Ljl+AR46tApWswN7QoUNpnxkzZnjbrdfD3rtp06bRPuw8tqLV7DyxfjqBHXPWdYRFh9n13Dquz9TgTz5qamqQlZWF+fPn0/tcdtllKCsri9xeeOGFhj6NiIiItFIN/uQjLy/P/D8K4L+zpbS0tG/0eCdPnqz3ozrWj++IiIhIy9ckaz5WrVqFXr16YdiwYbj99ttx5MgRet/8/HwkJSVFbtbHbSIiItLyNfrk47LLLsNzzz2HFStW4He/+x0KCgqQl5dHvyOaM2cOqqqqIjf2Hb+IiIi0Do1e2+W6666L/PeoUaMwevRoDBo0CKtWrcLkyZPPun9iYiJd1CIiIiKtT5MXlhs4cCBSUlKwa9cu7+SDcc55V12zdIi10pmt0LaKIbEV+VbSo3fv3t52awXyoUOHvO1WkSRWCMgq+Ma2WSv1rcdjghSWY8kDgCctrKJq7PFYcSmAJ26sVfxs31hRNyBYIUFWOM36OpOldKwV9Gylenp6Ou3DEj9WoqVPnz50GztXraKAPXv29LZb711GRoa33dpvlg6xzhM23qx4HMCTGWyfASA1NdXbHiTNZu0bKxJnXUc2b95Mt7Hxtr5+Z+NtJeoKCgoavG8syWUVCu3YsaO33Ur0sfQM+9sA8ONq2LBhtE+QtBYb06ikXRrqwIEDOHLkCP3DLCIiIrGlwZ98HD9+vN5Mrbi4GJs2bUL37t3RvXt3/OpXv8K0adOQlpaG3bt34+6778bgwYORm5vbqDsuIiIiLVODJx/r16/HRRddFPn37NmzAQDTp0/HggULsHnzZjz77LOorKxEeno6Lr30Uvz617/Wug4REREBEGDyceGFF5rf37/55pvfaodERESkdVNtFxEREQmVJh8iIiISqiaP2gb11Vdfeb/eYVE8FhsDePwnOzub9vl6sbxv8lgA8OGHH9JtDItg7du3j/Zhxa+sGKVVHIxhY23FgNn4sHgwYEdgWRTOilYHiS+zfbAKCbKIJ4vbAUDnzp297ePHj6d92PvKIrgAj6RbBdrYvlnYMWJFoa3SCyyWzorrATz+bn09zPpY1xH2mqxIZJBiXizSa70/bL+D/JyAFWtmxxUrdAYA+/fvp9tYJDwzM5P2GT58uLc9KyuL9mHxWGt82DXLOofY+2393di7d6+33YqKsyiytW/s/bbOE/Z+M1bc+Uz65ENERERCpcmHiIiIhEqTDxEREQmVJh8iIiISKk0+REREJFTNNu1SW1vrXcFtFWljOnTo4G0fN24c7TNq1Chv+4YNG2if7du3e9tLSkpoH7ZK3FodzVZhWyvoWfEgq5AWY+0b22alCKzkSk1Njbfdeq2scJm1cjslJcXbPnDgQNqHJVRYASeAJ2GshEynTp287VahMZbAYIXgAP7eHTx4kPYpLS31tu/evZv2YecWwF8rO4cBns4IUjTROq5Y6oglNqx9Y8cbwJNpVsE3ltay+rCUAyseB/DzmKWeAF7UDQD69+/vbV++fDntw96HQYMG0T7s/LIKhbLrrJUOCdKHFaK0ClSyY9tKm7C0n5UCtK7bPlZC50z65ENERERCpcmHiIiIhEqTDxEREQmVJh8iIiISKk0+REREJFTNLu1Styq4Ib8R/7+whIy1ypet+LZqGLDnsV5LkFoAbJv1PEFSQuzxrOdhq7qDvp9sv63Xw1ItVtqFPZ61epsdCyyhA/Dxsfqw57GSDGy/g6QfrHFjq+GDrLoHeJLB6sMSBlbaJTExscF9gqQF2DbrOsKOhSDHYpD3O0j6IcjzAPw4sR6PjY9Vp4U9j3Vss+PK6hOkfop1rWeCpF3YmAY5v5m6v5vW6408tvsm9wrRgQMHaNEcERERad5KSkrMnxwAmuHko7a2FqWlpejSpQvi4uJw7Ngx9OvXDyUlJWYGvzXTGGgMAI1BHY2DxgDQGADNbwycc6iurkZ6erpZZR1ohl+7tGnTxjtj6tq1a7MY3GjSGGgMAI1BHY2DxgDQGADNawySkpK+0f204FRERERCpcmHiIiIhKrZTz4SExMxd+5cujo9FmgMNAaAxqCOxkFjAGgMgJY9Bs1uwamIiIi0bs3+kw8RERFpXTT5EBERkVBp8iEiIiKh0uRDREREQqXJh4iIiISqWU8+5s+fj/79+6N9+/bIzs7GunXror1LTWr16tX43ve+h/T0dMTFxWHp0qX1tjvncP/996N3797o0KEDpkyZgp07d0ZnZ5tAfn4+xo8fjy5duqBXr1648sorsWPHjnr3+eKLLzBjxgz06NEDnTt3xrRp01BRURGlPW4aCxYswOjRoyO/WpiTk4M33ngjsj0WxuBMDz/8MOLi4nDXXXdF2lr7ODzwwAOIi4urdxs+fHhke2t//XUOHjyIG2+8ET169ECHDh0watQorF+/PrK9tV8XAaB///5nHQtxcXGYMWMGgJZ5LDTbyceLL76I2bNnY+7cudiwYQOysrKQm5uLQ4cORXvXmkxNTQ2ysrIwf/587/ZHHnkEjz/+OBYuXIjCwkJ06tQJubm5ZhXKlqSgoAAzZszA2rVrsXz5cnz55Ze49NJL61Wx/MlPfoJXX30VL7/8MgoKClBaWoqrr746invd+Pr27YuHH34YRUVFWL9+PS6++GJMnToVH330EYDYGIOv++CDD/CnP/0Jo0ePrtceC+MwcuRIlJWVRW7vvvtuZFssvP6jR49i4sSJaNeuHd544w1s27YNv//979GtW7fIfVr7dRH47znw9eNg+fLlAIBrrrkGQAs9FlwzNWHCBDdjxozIv0+fPu3S09Ndfn5+FPcqPADckiVLIv+ura11aWlpbt68eZG2yspKl5iY6F544YUo7GHTO3TokAPgCgoKnHP/fb3t2rVzL7/8cuQ+27dvdwDcmjVrorWboejWrZt76qmnYm4Mqqur3ZAhQ9zy5cvdBRdc4GbNmuWci41jYe7cuS4rK8u7LRZev3PO3XPPPW7SpEl0eyxeF51zbtasWW7QoEGutra2xR4LzfKTj1OnTqGoqAhTpkyJtLVp0wZTpkzBmjVrorhn0VNcXIzy8vJ6Y5KUlITs7OxWOyZVVVUAgO7duwMAioqK8OWXX9Ybg+HDhyMjI6PVjsHp06exePFi1NTUICcnJ+bGYMaMGbj88svrvV4gdo6FnTt3Ij09HQMHDsQNN9yA/fv3A4id1//KK69g3LhxuOaaa9CrVy+MGTMGTz75ZGR7LF4XT506heeffx4333wz4uLiWuyx0CwnH4cPH8bp06eRmpparz01NRXl5eVR2qvoqnvdsTImtbW1uOuuuzBx4kSce+65AP47BgkJCUhOTq5339Y4Blu2bEHnzp2RmJiI2267DUuWLMGIESNiagwWL16MDRs2ID8//6xtsTAO2dnZWLRoEZYtW4YFCxaguLgY559/Pqqrq2Pi9QPAnj17sGDBAgwZMgRvvvkmbr/9dtx555149tlnAcTedREAli5disrKStx0000AWu65EB/tHRDxmTFjBrZu3VrvO+5YMmzYMGzatAlVVVX4+9//junTp6OgoCDauxWakpISzJo1C8uXL0f79u2jvTtRkZeXF/nv0aNHIzs7G5mZmXjppZfQoUOHKO5ZeGprazFu3Dj89re/BQCMGTMGW7duxcKFCzF9+vQo7110/OUvf0FeXh7S09OjvSvfSrP85CMlJQVt27Y9a7VuRUUF0tLSorRX0VX3umNhTGbOnInXXnsNK1euRN++fSPtaWlpOHXqFCorK+vdvzWOQUJCAgYPHoyxY8ciPz8fWVlZ+MMf/hAzY1BUVIRDhw7hO9/5DuLj4xEfH4+CggI8/vjjiI+PR2pqakyMw9clJydj6NCh2LVrV8wcB71798aIESPqtZ1zzjmRr59i6boIAPv27cPbb7+NH/3oR5G2lnosNMvJR0JCAsaOHYsVK1ZE2mpra7FixQrk5OREcc+iZ8CAAUhLS6s3JseOHUNhYWGrGRPnHGbOnIklS5bgnXfewYABA+ptHzt2LNq1a1dvDHbs2IH9+/e3mjFgamtrcfLkyZgZg8mTJ2PLli3YtGlT5DZu3DjccMMNkf+OhXH4uuPHj2P37t3o3bt3zBwHEydOPCtu/8knnyAzMxNAbFwXv+6ZZ55Br169cPnll0faWuyxEO0Vr8zixYtdYmKiW7Rokdu2bZu79dZbXXJysisvL4/2rjWZ6upqt3HjRrdx40YHwD366KNu48aNbt++fc455x5++GGXnJzs/vWvf7nNmze7qVOnugEDBrgTJ05Eec8bx+233+6SkpLcqlWrXFlZWeT2+eefR+5z2223uYyMDPfOO++49evXu5ycHJeTkxPFvW589957rysoKHDFxcVu8+bN7t5773VxcXHurbfecs7Fxhj4fD3t4lzrH4ef/vSnbtWqVa64uNi99957bsqUKS4lJcUdOnTIOdf6X79zzq1bt87Fx8e73/zmN27nzp3ur3/9q+vYsaN7/vnnI/dp7dfFOqdPn3YZGRnunnvuOWtbSzwWmu3kwznn/vjHP7qMjAyXkJDgJkyY4NauXRvtXWpSK1eudADOuk2fPt05999Y2X333edSU1NdYmKimzx5stuxY0d0d7oR+V47APfMM89E7nPixAl3xx13uG7durmOHTu6q666ypWVlUVvp5vAzTff7DIzM11CQoLr2bOnmzx5cmTi4VxsjIHPmZOP1j4O1157revdu7dLSEhwffr0cddee63btWtXZHtrf/11Xn31VXfuuee6xMREN3z4cPfnP/+53vbWfl2s8+abbzoA3tfWEo+FOOeci8pHLiIiIhKTmuWaDxEREWm9NPkQERGRUGnyISIiIqHS5ENERERCpcmHiIiIhEqTDxEREQmVJh8iIiISKk0+REREJFSafIiIiEioNPkQERGRUGnyISIiIqH6P7Kxv6Ye/HruAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1345af1f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.hstack(load_folder(\"train/face\")[:4]), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(np.hstack(load_folder(\"train/non-face\")[:4]), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb68d2b6-fd69-4a71-b2cd-bd24ce7eeafb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Adaboost\n",
    "In this detector we train a set of weak classifiers (ridge classifier) on a set of features and then ensemble them using the adaboost classifier.\n",
    "The algorithm works as follows:\n",
    "1. Continue iterations until limit, or no FP:\n",
    "2. In each iteration train the model on the weighted training data\n",
    "3. Recompute the weights based on performance of the model and keep repeating until 1.\n",
    "\n",
    "Once the iterations are done a strong classifier is formed which is ensemble of each of the weak classifiers trained during the iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68523c06-386e-45a7-8e48-dd3efe5afbc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Adaboost(train_x, train_y, d=1, T=100):\n",
    "    # Count number of positive and negative examples in the training set\n",
    "    face_count = 0\n",
    "    non_face_count = 0\n",
    "    for i, label in enumerate(train_y):\n",
    "        if label:\n",
    "            face_count += 1\n",
    "        else:\n",
    "            non_face_count += 1\n",
    "    # Print number of positive and negative examples\n",
    "    print(face_count, non_face_count)\n",
    "\n",
    "    # Initialize weights for each example in the training set\n",
    "    w = np.array([1/face_count if train_y[i] else 1/non_face_count for i in range(len(train_y))])\n",
    "\n",
    "    # Initialize lists to hold classifiers, feature selections, and betas\n",
    "    classifiers = []\n",
    "    feature_sel = []\n",
    "    betas = []\n",
    "    model_threshold = 0\n",
    "\n",
    "    # Define function to select features given a list of data and a list of selected feature indices\n",
    "    def select_features(x_data, x_sel):\n",
    "        return [np.hstack([x[f] for f in x_sel]) for x in x_data]\n",
    "\n",
    "    # Initialize predictions to be an array of zeros with the same shape as the training labels\n",
    "    predictions = np.zeros(train_y.shape)\n",
    "\n",
    "    # Iterate T times to create T classifiers\n",
    "    for t in range(T):\n",
    "        # Normalize weights to sum to 1\n",
    "        w = w / np.sum(w)\n",
    "\n",
    "        # Repeat until beta < 0.5 (i.e. the classifier performs better than random)\n",
    "        while True:\n",
    "            # Initialize a RidgeClassifier and randomly select d features from the training set\n",
    "            model = RidgeClassifier()\n",
    "            m_sel = np.random.permutation(len(train_x[0]))[:d]\n",
    "            m_train_x = select_features(train_x, m_sel)\n",
    "\n",
    "            # Fit the model to the training data with weights w\n",
    "            model.fit(m_train_x, train_y, sample_weight=w)\n",
    "\n",
    "            # Compute error for each example in the training set\n",
    "            e = np.abs(train_y - model.predict(m_train_x))\n",
    "\n",
    "            # Compute beta, the weighted error of the classifier\n",
    "            beta = np.sum(w * e)\n",
    "\n",
    "            # If the beta is less than 0.5, store the classifier, selected features, and beta\n",
    "            if beta < 0.5:\n",
    "                feature_sel.append(m_sel)\n",
    "                w = w * np.power(beta, 1-e)\n",
    "                classifiers.append(model)\n",
    "                betas.append(beta+1e-6)\n",
    "                break\n",
    "\n",
    "        # Compute alpha, the weight of the current classifier\n",
    "        alpha = -np.log(betas)\n",
    "\n",
    "        # Update predictions with the current classifier's predictions weighted by alpha\n",
    "        predictions = predictions + alpha[-1]*np.array(classifiers[-1].predict(select_features(train_x, feature_sel[-1])))\n",
    "\n",
    "        # Compute the model threshold as the minimum prediction value for positive examples\n",
    "        model_threshold = np.min(predictions[train_y==1])\n",
    "\n",
    "        # Compute the number of misclassified examples\n",
    "        miss_classification = np.sum((predictions >= model_threshold) != train_y)\n",
    "\n",
    "        # Print the current error rate\n",
    "        print(f'Training Error at round {t}: {miss_classification}')\n",
    "\n",
    "        # If there are no misclassified examples, stop iterating\n",
    "        if miss_classification == 0:\n",
    "            break\n",
    "\n",
    "    # Define a function to return the final model, which makes predictions based on the weighted sum of all T classifiers\n",
    "    def model(x):\n",
    "        preds = np.sum( np.array([c.predict(select_features(x, f_sel)) for c, f_sel in zip(classifiers, feature_sel)]) * alpha.reshape(-1,1), axis=0)\n",
    "        return preds >= model_threshold\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b41899-addf-4efb-8710-3fd28a6b9ed1",
   "metadata": {},
   "source": [
    "## Training the Cascade\n",
    "\n",
    "Now inorder, to further improve the performance and at the same time the accuracy, strong classifiers (trained using adaboost) are cascaded.\n",
    "\n",
    "How do they improve the performance?\n",
    "The earlier stages are trained using a smaller no. of features compared to the later stages, every feature rich models are tuned, the implied performance benefit is that as soon as a instance is classified as false, it is removed from the pipeline saving future computation of further futures thereby given significant performance gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e492c69f-18be-4ca3-8c01-895b9ffd4406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "haar_filters = generate_haar_filters()\n",
    "np.random.shuffle(haar_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "185adb16-b6a7-4563-9b03-686dc7d3b871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = train_x\n",
    "y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb5c0bc6-c460-4252-adc9-7e52a6f258dc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: 2 - 600\n",
      "training start:\n",
      "2429 1850\n",
      "Training Error at round 0: 1850\n",
      "Training Error at round 1: 1850\n",
      "Training Error at round 2: 1850\n",
      "Training Error at round 3: 892\n",
      "Training Error at round 4: 892\n",
      "Training Error at round 5: 946\n",
      "Training Error at round 6: 685\n",
      "Training Error at round 7: 635\n",
      "Training Error at round 8: 521\n",
      "Training Error at round 9: 406\n",
      "Training Error at round 10: 509\n",
      "Training Error at round 11: 373\n",
      "Training Error at round 12: 432\n",
      "Training Error at round 13: 365\n",
      "Training Error at round 14: 390\n",
      "Training Error at round 15: 283\n",
      "Training Error at round 16: 340\n",
      "Training Error at round 17: 288\n",
      "Training Error at round 18: 329\n",
      "Training Error at round 19: 250\n",
      "Training Error at round 20: 258\n",
      "Training Error at round 21: 241\n",
      "Training Error at round 22: 254\n",
      "Training Error at round 23: 213\n",
      "Training Error at round 24: 184\n",
      "Training Error at round 25: 191\n",
      "Training Error at round 26: 192\n",
      "Training Error at round 27: 183\n",
      "Training Error at round 28: 145\n",
      "Training Error at round 29: 182\n",
      "Training Error at round 30: 148\n",
      "Training Error at round 31: 172\n",
      "Training Error at round 32: 167\n",
      "Training Error at round 33: 170\n",
      "Training Error at round 34: 138\n",
      "Training Error at round 35: 177\n",
      "Training Error at round 36: 169\n",
      "Training Error at round 37: 179\n",
      "Training Error at round 38: 173\n",
      "Training Error at round 39: 184\n",
      "Training Error at round 40: 146\n",
      "Training Error at round 41: 113\n",
      "Training Error at round 42: 127\n",
      "Training Error at round 43: 143\n",
      "Training Error at round 44: 140\n",
      "Training Error at round 45: 98\n",
      "Training Error at round 46: 132\n",
      "Training Error at round 47: 184\n",
      "Training Error at round 48: 137\n",
      "Training Error at round 49: 89\n",
      "Training Error at round 50: 117\n",
      "Training Error at round 51: 89\n",
      "Training Error at round 52: 127\n",
      "Training Error at round 53: 128\n",
      "Training Error at round 54: 108\n",
      "Training Error at round 55: 82\n",
      "Training Error at round 56: 111\n",
      "Training Error at round 57: 65\n",
      "Training Error at round 58: 100\n",
      "Training Error at round 59: 67\n",
      "Training Error at round 60: 88\n",
      "Training Error at round 61: 71\n",
      "Training Error at round 62: 80\n",
      "Training Error at round 63: 86\n",
      "Training Error at round 64: 77\n",
      "Training Error at round 65: 84\n",
      "Training Error at round 66: 70\n",
      "Training Error at round 67: 65\n",
      "Training Error at round 68: 63\n",
      "Training Error at round 69: 43\n",
      "Training Error at round 70: 60\n",
      "Training Error at round 71: 43\n",
      "Training Error at round 72: 66\n",
      "Training Error at round 73: 36\n",
      "Training Error at round 74: 56\n",
      "Training Error at round 75: 27\n",
      "Training Error at round 76: 57\n",
      "Training Error at round 77: 25\n",
      "Training Error at round 78: 50\n",
      "Training Error at round 79: 69\n",
      "Training Error at round 80: 52\n",
      "Training Error at round 81: 48\n",
      "Training Error at round 82: 47\n",
      "Training Error at round 83: 52\n",
      "Training Error at round 84: 37\n",
      "Training Error at round 85: 20\n",
      "Training Error at round 86: 33\n",
      "Training Error at round 87: 22\n",
      "Training Error at round 88: 26\n",
      "Training Error at round 89: 20\n",
      "Training Error at round 90: 10\n",
      "Training Error at round 91: 6\n",
      "Training Error at round 92: 4\n",
      "Training Error at round 93: 5\n",
      "Training Error at round 94: 0\n",
      "---------------\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "cascade_models = [] # list to store the final cascade of models\n",
    "cascade_filter_prefix = [] # list to store the number of filters used in each stage\n",
    "\n",
    "filter_size = 200 # initial size of filters for the first stage\n",
    "stage_filters = [] # list to store filters for each stage\n",
    "feature_x = [[] for x in train_x] # list to store computed Haar features for each sample\n",
    "\n",
    "# loop until convergence (no FP)\n",
    "while True: \n",
    "    # Add filters to the current stage filter list\n",
    "    stage_filters += haar_filters[:filter_size] \n",
    "    print(f\"Stage: {len(cascade_models)+1} - {len(stage_filters)}\")\n",
    "    \n",
    "    # Compute Haar features for each sample using current set of filters\n",
    "    feature_x = [ feature_x[i]+compute_haar_coef(train_x[i], haar_filters[:filter_size]) for i in range(len(feature_x))] \n",
    "\n",
    "    print(\"training start:\")\n",
    "\n",
    "    # Train Adaboost model\n",
    "    model=Adaboost(feature_x, y, len(stage_filters)//10, 200) \n",
    "\n",
    "    print(\"---------------\")\n",
    "    \n",
    "    # Add trained model and no. of filter used to the cascade model list\n",
    "    cascade_models.append(model) \n",
    "    cascade_filter_prefix.append(len(stage_filters))\n",
    "    \n",
    "    \n",
    "    # Remove filters used in this stage from list of available filters\n",
    "    haar_filters = haar_filters[filter_size+1:] \n",
    "    \n",
    "    # Update filter size for next stag\n",
    "    filter_size = min(filter_size*2, len(haar_filters)) \n",
    "\n",
    "    # Predict labels for current set of features\n",
    "    y_pred = model(feature_x) \n",
    "\n",
    "    # Extract all positive marked (TP and FP) samples and use them to train the next cascade of classifier\n",
    "    pos_sample = np.argwhere(y_pred==True).flatten() # indices of positive samples\n",
    "\n",
    "    new_x = [x[i] for i in pos_sample]\n",
    "    new_y = [y[i] for i in pos_sample]\n",
    "    feature_x = [feature_x[i] for i in pos_sample]\n",
    "\n",
    "    # if all labels are correctly predicted, terminate\n",
    "    if( (y_pred==y).all() ): \n",
    "        break\n",
    "\n",
    "    # set new set of samples for next stage\n",
    "    x = new_x\n",
    "    y = np.array(new_y)\n",
    "    \n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c1c276d-232c-404f-aac1-c5a50075ac7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<function Adaboost.<locals>.model at 0x1341e4550>, <function Adaboost.<locals>.model at 0x133e1beb0>]\n"
     ]
    }
   ],
   "source": [
    "print(cascade_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a58428c2-baa4-4c30-9520-97b1cdf0829d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_img(img):\n",
    "    # Compute the integral image\n",
    "    intg_img = compute_intg_image(img)\n",
    "    # Initialize some variables\n",
    "    filt_size = 100\n",
    "    t_filt = cascade_filter_prefix[0]\n",
    "    feature_x = []\n",
    "    p_filt = 0\n",
    "    # Loop over the cascade models\n",
    "    for i in range(len(cascade_models)):\n",
    "        # Select the filters for the current stage\n",
    "        s_f = stage_filters[p_filt:t_filt]\n",
    "        # If there are filters, compute the Haar features\n",
    "        if len(s_f) > 0:\n",
    "            feature_x += compute_haar_coef(intg_img, s_f)\n",
    "        # Update the filter index variables\n",
    "        p_filt = t_filt\n",
    "        if i+1 < len(cascade_filter_prefix):\n",
    "            t_filt = cascade_filter_prefix[i+1]\n",
    "        # Check if the image passes the current stage of the cascade model\n",
    "        if not(cascade_models[i]([feature_x])):\n",
    "            return False\n",
    "    # If the image passes all stages, return True\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0e3b1-9407-4bad-ae36-b9a8d8ecb21d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Demo Code\n",
    "This code launches a live window with live web cam feed to continously run and display the detected faces by marking them using a bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbdc997-c8c7-4a49-b604-59fe6d9a1b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "      \n",
    "    # Read webcam frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    # Convert the frame to grayscale and resize it\n",
    "    img = cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), (200,200), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Create a copy of the image to draw bounding boxes on\n",
    "    cimg = img.copy()\n",
    "    \n",
    "    # Set the size of the kernel used for scanning the image\n",
    "    k_size = 80\n",
    "    \n",
    "    # Loop through the image using the kernel with some overlap\n",
    "    for i in range(0,img.shape[0]-k_size+1, k_size//2):\n",
    "        for j in range(0,img.shape[1]-k_size+1, k_size//2):\n",
    "            \n",
    "            # Check if the current sub-image matches the object being searched for\n",
    "            if(check_img(cv2.resize(cv2.equalizeHist(img[i:i+k_size, j:j+k_size]), (19,19), interpolation=cv2.INTER_AREA) )):\n",
    "                \n",
    "                # If the sub-image matches, draw a bounding box on the copy of the image\n",
    "                cv2.rectangle(cimg, (j,i), (j+k_size, i+k_size), 255, 2)\n",
    "    \n",
    "    # Display the image with the bounding boxes\n",
    "    cv2.imshow('frame', cimg)\n",
    "    \n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e3350-3958-43a4-81a1-7d68c0364266",
   "metadata": {},
   "source": [
    "## Test Performance\n",
    "We will now evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ac3c18d-e141-49be-8cfd-6677b9877f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 00:02:07.090 Python[61400:4464187] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/17/kf9r_zz559j0trllxywmgmq00000gn/T/org.python.python.savedState\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m kimg \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrectangle(cimg\u001b[38;5;241m.\u001b[39mcopy(), (j,i), (j\u001b[38;5;241m+\u001b[39mk_size, i\u001b[38;5;241m+\u001b[39mk_size), \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Check if the current sub-image matches the object being searched for\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[43mcheck_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m:\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTER_AREA\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m ):\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# If the sub-image matches, draw a bounding box on the copy of the image\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(cimg, (j,i), (j\u001b[38;5;241m+\u001b[39mk_size, i\u001b[38;5;241m+\u001b[39mk_size), \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     15\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcimg\u001b[39m\u001b[38;5;124m\"\u001b[39m,kimg)\n",
      "Cell \u001b[0;32mIn[17], line 21\u001b[0m, in \u001b[0;36mcheck_img\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     19\u001b[0m         t_filt \u001b[38;5;241m=\u001b[39m cascade_filter_prefix[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Check if the image passes the current stage of the cascade model\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(\u001b[43mcascade_models\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_x\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# If the image passes all stages, return True\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 79\u001b[0m, in \u001b[0;36mAdaboost.<locals>.model\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel\u001b[39m(x):\n\u001b[0;32m---> 79\u001b[0m     preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum( np\u001b[38;5;241m.\u001b[39marray([c\u001b[38;5;241m.\u001b[39mpredict(select_features(x, f_sel)) \u001b[38;5;28;01mfor\u001b[39;00m c, f_sel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classifiers, feature_sel)]) \u001b[38;5;241m*\u001b[39m alpha\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m model_threshold\n",
      "Cell \u001b[0;32mIn[10], line 79\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel\u001b[39m(x):\n\u001b[0;32m---> 79\u001b[0m     preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum( np\u001b[38;5;241m.\u001b[39marray([\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselect_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_sel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c, f_sel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classifiers, feature_sel)]) \u001b[38;5;241m*\u001b[39m alpha\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m model_threshold\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1212\u001b[0m, in \u001b[0;36m_RidgeClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1210\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_binarizer\u001b[38;5;241m.\u001b[39minverse_transform(scores)\n\u001b[0;32m-> 1212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:419\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 419\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    421\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:401\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    398\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m    400\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 401\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:192\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 192\u001b[0m     \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m ):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/scipy/sparse/_base.py:1301\u001b[0m, in \u001b[0;36misspmatrix\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1298\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m-> 1301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misspmatrix\u001b[39m(x):\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is x of a sparse matrix type?\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m \n\u001b[1;32m   1304\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, spmatrix)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "frame = cv2.imread(\"test_2.jpeg\")\n",
    "img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "cimg = img.copy()\n",
    "\n",
    "k_size = 66\n",
    "# Loop through the image using the kernel with some overlap\n",
    "for i in range(0,img.shape[0]-k_size+1, k_size//2):\n",
    "    for j in range(0,img.shape[1]-k_size+1, k_size//2):\n",
    "        kimg = cv2.rectangle(cimg.copy(), (j,i), (j+k_size, i+k_size), 255, 2)\n",
    "        # Check if the current sub-image matches the object being searched for\n",
    "        if(check_img(cv2.resize(img[i:i+k_size, j:j+k_size], (19,19), interpolation=cv2.INTER_AREA)) ):\n",
    "\n",
    "            # If the sub-image matches, draw a bounding box on the copy of the image\n",
    "            cv2.rectangle(cimg, (j,i), (j+k_size, i+k_size), 255, 2)\n",
    "        cv2.imshow(\"cimg\",kimg)\n",
    "        cv2.waitKey(1)\n",
    "cv2.imshow(\"cimg\",cimg)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9dd89-895f-4dec-9e5b-20e8815faa04",
   "metadata": {
    "tags": []
   },
   "source": [
    "## References\n",
    "1. https://docs.opencv.org/3.4/d2/d99/tutorial_js_face_detection.html\n",
    "2. P. Viola and M. Jones, \"Rapid object detection using a boosted cascade of simple features,\" Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001, Kauai, HI, USA, 2001, pp. I-I, doi: 10.1109/CVPR.2001.990517.\n",
    "3. https://towardsdatascience.com/face-detection-with-haar-cascade-727f68dafd08\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
